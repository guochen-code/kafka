each record has a unique key, for any future record, if the key matches with the key of any record in the log
the existing one in the log will be deleted and the new record will be written into the log
order of all the messages will not be changed

******************* lab , ec2
wget https://dlcdn.apache.org/kafka/3.4.0/...
tar -xvf kafka_2.13-3.4.0.tgz


To install Java --
----------------------------------------
java -version
sudo yum install java-1.8.0-openjdk
java -version
cd kafka_2.13-3.4.0

Start Zoo-keeper:
-------------------------------
bin/zookeeper-server-start.sh config/zookeeper.properties


Start Kafka-server:
----------------------------------------
Duplicate the session & enter in a new console --
export KAFKA_HEAP_OPTS="-Xmx256M -Xms128M"
cd kafka_2.13-3.4.0
bin/kafka-server-start.sh config/server.properties

It is pointing to private server , change server.properties so that it can run in public IP 

To do this , you can follow any of the 2 approaches shared belwo --
1)Do a vi config/server.properties in insert mode -- change ADVERTISED_LISTENERS to public ip of the EC2 instance
2)You can modify the file using Winscp also

To create Log Compacted Topic:
--------------------------------------
cd kafka_2.13-3.4.0
bin/kafka-topics.sh --create --topic demo_testing3 --bootstrap-server 54.90.61.129:9092 --replication-factor 1 --partitions 1 
--config cleanup.policy=compact --config min.cleanable.dirty.ratio=0.001 --config segment.ms=5000
# min.cleanable.dirty.ratio=0.001, just for demonstration purpose, just show you the log compact is happening
# if min.cleanable.dirty.ratio=0.5, means at least 50% of your topic and partition data have data entry for compaction to run
# data entry: for one particular key, multiple entries are there
# each new log segment will be created every segment.ms=5000

To Start the Producer:
-------------------------
bin/kafka-console-producer.sh --topic demo_testing3 --bootstrap-server 54.90.61.129:9092 
--property parse.key=true --property key.separator=,

To Start the Consumer:
-------------------------
cd kafka_2.13-3.4.0
bin/kafka-console-consumer.sh --topic demo_testing3 --from-beginning --bootstrap-server 54.90.61.129:9092 
--property print.key=true --property key.separator=,

# if replacement happened, once a new consumer is started, it will not see the old value, because already been deleted

